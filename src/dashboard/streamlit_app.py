import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import numpy as np
import os

# --- 1. CONFIGURATION DE LA PAGE ---
st.set_page_config(
    page_title="Vietnam Air Quality AI",
    page_icon="ğŸ‡»ğŸ‡³",
    layout="wide"
)

# --- 2. FONCTIONS UTILITAIRES ---

def get_aqi_color(aqi):
    """Retourne la couleur standard AQI"""
    if aqi <= 50: return "#00E400"  # Good (Green)
    elif aqi <= 100: return "#FFFF00" # Moderate (Yellow)
    elif aqi <= 150: return "#FF7E00" # Unhealthy for Sensitive (Orange)
    elif aqi <= 200: return "#FF0000" # Unhealthy (Red)
    elif aqi <= 300: return "#8F3F97" # Very Unhealthy (Purple)
    else: return "#7E0023" # Hazardous (Maroon)

@st.cache_data
def load_archive_data():
    """
    Charge le CSV historique.
    Cherche dans plusieurs dossiers possibles pour Ã©viter les erreurs de chemin.
    """
    possible_paths = [
        "data/aqi_data.csv",           # Chemin standard demandÃ©
        "src/data/aqi_data.csv",       # Autre structure commune
        "aqi_data.csv"                 # Racine
    ]
    
    df = None
    used_path = ""

    for path in possible_paths:
        if os.path.exists(path):
            try:
                df = pd.read_csv(path)
                used_path = path
                break
            except:
                continue
    
    if df is not None:
        # Nettoyage et conversion
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        # On force les colonnes numÃ©riques
        cols_num = ['aqi', 'pm25', 'pm10', 'co', 'no2', 'so2', 'o3']
        for col in cols_num:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        return df.dropna()
    else:
        return None

def init_connection():
    """Connexion Ã  NeonDB pour le Live"""
    return st.connection("postgresql", type="sql")

def load_live_data(conn):
    """RÃ©cupÃ¨re les donnÃ©es fraiches de Neon"""
    try:
        # On ne charge que les 1000 derniÃ¨res lignes pour aller vite
        return conn.query('SELECT * FROM aqi_data ORDER BY timestamp DESC LIMIT 1000;', ttl="10m")
    except:
        return pd.DataFrame() # Retourne vide si erreur ou table vide

# --- 3. INTERFACE & NAVIGATION ---

st.sidebar.title("ğŸ” Navigation")
page = st.sidebar.radio("Aller vers :", ["ğŸ“Š Archives & Performance IA", "ğŸ”´ Live Data (Temps RÃ©el)"])

st.sidebar.markdown("---")
st.sidebar.info("Projet : Vietnam Air Quality Forecasting")

# ==============================================================================
# PAGE 1 : ARCHIVES & PERFORMANCE (Le Laboratoire IA)
# ==============================================================================
if page == "ğŸ“Š Archives & Performance IA":
    st.title("ğŸ§  Analyse de Performance du ModÃ¨le")
    st.markdown("""
    Cette section utilise les **donnÃ©es historiques (CSV)** pour prouver l'efficacitÃ© de l'IA.
    Nous voyageons dans le passÃ© pour voir si le modÃ¨le aurait pu prÃ©dire la pollution rÃ©elle.
    """)

    df = load_archive_data()

    if df is not None:
        # --- A. Filtres ---
        col_filters1, col_filters2 = st.columns(2)
        with col_filters1:
            locations = df['location'].unique()
            selected_location = st.selectbox("ğŸ“ Choisir une ville", locations)
        
        # Filtrer par lieu
        df_loc = df[df['location'] == selected_location].sort_values('timestamp')
        
        with col_filters2:
            # SÃ©lecteur de date intelligent
            min_date = df_loc['timestamp'].min().date()
            max_date = df_loc['timestamp'].max().date()
            test_date = st.date_input("ğŸ“… Date Ã  prÃ©dire (Test)", max_date, min_value=min_date, max_value=max_date)

        # --- B. Simulation IA ---
        # On coupe les donnÃ©es : Tout ce qui est AVANT la date sert Ã  apprendre
        split_date = pd.Timestamp(test_date)
        train_df = df_loc[df_loc['timestamp'] < split_date]
        test_df = df_loc[df_loc['timestamp'].dt.date == split_date]

        if len(train_df) > 100 and len(test_df) > 0:
            
            with st.spinner('L\'IA analyse le passÃ© et gÃ©nÃ¨re ses prÃ©dictions...'):
                features = ['pm25', 'no2', 'so2', 'co', 'o3'] 
                target = 'aqi'
                
                # VÃ©rifier que les colonnes existent
                available_features = [f for f in features if f in df.columns]
                
                X_train = train_df[available_features]
                y_train = train_df[target]
                X_test = test_df[available_features]
                y_test = test_df[target]

                # EntraÃ®nement Random Forest
                model = RandomForestRegressor(n_estimators=50, random_state=42)
                model.fit(X_train, y_train)
                
                # PrÃ©diction
                y_pred = model.predict(X_test)
                test_df = test_df.copy()
                test_df['predicted_aqi'] = y_pred

            # --- C. RÃ©sultats ---
            
            # 1. MÃ©triques
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            st.markdown("### ğŸ¯ Score de PrÃ©cision")
            col1, col2, col3 = st.columns(3)
            col1.metric("Date AnalysÃ©e", f"{test_date}")
            col2.metric("PrÃ©cision (RÂ²)", f"{r2:.2f}", delta_color="normal", help="Proche de 1 = Parfait")
            col3.metric("Erreur Moyenne (MAE)", f"{mae:.1f}", delta="-Good" if mae < 15 else "inverse", help="Plus c'est bas, mieux c'est")

            # 2. Graphique Principal
            st.subheader(f"ğŸ“‰ RÃ©alitÃ© vs PrÃ©diction Ã  {selected_location}")
            
            fig = go.Figure()
            # Ligne RÃ©elle
            fig.add_trace(go.Scatter(
                x=test_df['timestamp'], y=test_df['aqi'],
                mode='lines+markers', name='RÃ©alitÃ© (MesurÃ©)',
                line=dict(color='#1f77b4', width=3)
            ))
            # Ligne PrÃ©dite
            fig.add_trace(go.Scatter(
                x=test_df['timestamp'], y=test_df['predicted_aqi'],
                mode='lines', name='PrÃ©diction IA',
                line=dict(color='#ff7f0e', width=3, dash='dot')
            ))
            fig.update_layout(xaxis_title="Heure", yaxis_title="AQI", hovermode="x unified")
            st.plotly_chart(fig, use_container_width=True)

            # 3. Explication (Feature Importance)
            with st.expander("Voir comment l'IA a rÃ©flÃ©chi (Importance des Polluants)"):
                importance = pd.DataFrame({
                    'Polluant': available_features,
                    'Importance': model.feature_importances_
                }).sort_values(by='Importance', ascending=True)
                
                fig_imp = px.bar(importance, x='Importance', y='Polluant', orientation='h', 
                                 title="Poids des polluants dans la dÃ©cision", color='Importance')
                st.plotly_chart(fig_imp, use_container_width=True)

        else:
            if len(train_df) <= 100:
                st.warning("âš ï¸ Pas assez de donnÃ©es historiques AVANT cette date pour entraÃ®ner l'IA. Choisissez une date plus rÃ©cente.")
            else:
                st.warning("âš ï¸ Pas de donnÃ©es disponibles pour la date exacte sÃ©lectionnÃ©e.")

    else:
        st.error("âŒ Impossible de trouver le fichier 'aqi_data.csv'. VÃ©rifiez qu'il est bien dans le dossier 'data/' sur GitHub.")

# ==============================================================================
# PAGE 2 : LIVE DATA (NeonDB)
# ==============================================================================
elif page == "ğŸ”´ Live Data (Temps RÃ©el)":
    st.title("ğŸ“¡ Monitoring en Temps RÃ©el")
    st.markdown("Connexion directe Ã  la base de donnÃ©es **NeonDB**. Les donnÃ©es apparaissent ici dÃ¨s qu'elles sont collectÃ©es par le scraper.")

    conn = init_connection()
    df_live = load_live_data(conn)

    if not df_live.empty:
        # Conversion date
        df_live['timestamp'] = pd.to_datetime(df_live['timestamp'])
        
        # Dernier relevÃ©
        latest_time = df_live['timestamp'].max()
        st.success(f"DerniÃ¨re mise Ã  jour reÃ§ue : {latest_time}")

        # KPI Cards pour les villes principales
        st.subheader("ğŸŒ Situation Actuelle")
        
        # On prend les donnÃ©es les plus rÃ©centes par ville
        latest_data = df_live.sort_values('timestamp', ascending=False).drop_duplicates('location').head(4)
        
        cols = st.columns(len(latest_data))
        for index, (i, row) in enumerate(latest_data.iterrows()):
            with cols[index]:
                aqi_val = row['aqi'] if pd.notna(row['aqi']) else 0
                color = get_aqi_color(aqi_val)
                st.markdown(f"""
                <div style="background-color: {color}; padding: 15px; border-radius: 10px; color: black; text-align: center; box-shadow: 2px 2px 5px rgba(0,0,0,0.1);">
                    <h3 style="margin:0;">{row['location']}</h3>
                    <h1 style="font-size: 3em; margin:0;">{int(aqi_val)}</h1>
                    <p style="margin:0;">AQI</p>
                </div>
                """, unsafe_allow_html=True)

        # Tableau de donnÃ©es brutes
        st.markdown("### ğŸ“ Historique RÃ©cent (Live)")
        st.dataframe(df_live, use_container_width=True)
        
        if st.button("ğŸ”„ Actualiser maintenant"):
            st.rerun()

    else:
        # Affichage Ã©lÃ©gant quand la base est vide
        st.info("ğŸ‘‹ Bienvenue sur le Dashboard Live !")
        st.warning("â³ La base de donnÃ©es est actuellement en attente de donnÃ©es.")
        
        st.markdown("""
        ### Statut du systÃ¨me :
        * **Base de donnÃ©es :** ConnectÃ©e âœ…
        * **Table aqi_data :** DÃ©tectÃ©e âœ…
        * **DonnÃ©es :** En attente du premier passage du robot ğŸ¤–
        
        Le scraper automatique va bientÃ´t remplir cette page. En attendant, vous pouvez consulter l'onglet **"Archives & Performance IA"** pour voir le modÃ¨le travailler sur l'historique.
        """)
