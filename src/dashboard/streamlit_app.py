import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import numpy as np

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(
    page_title="Vietnam Air Quality AI",
    page_icon="üáªüá≥",
    layout="wide"
)

# --- FONCTIONS UTILITAIRES ---

def get_aqi_color(aqi):
    if aqi <= 50: return "#00E400"  # Good (Green)
    elif aqi <= 100: return "#FFFF00" # Moderate (Yellow)
    elif aqi <= 150: return "#FF7E00" # Unhealthy for Sensitive (Orange)
    elif aqi <= 200: return "#FF0000" # Unhealthy (Red)
    elif aqi <= 300: return "#8F3F97" # Very Unhealthy (Purple)
    else: return "#7E0023" # Hazardous (Maroon)

# --- CHARGEMENT DES DONN√âES ---

@st.cache_data
def load_archive_data():
    """Charge le CSV local pour la partie Analyse/Archive"""
    try:
        # Assure-toi que le fichier s'appelle bien 'aqi_data.csv' et est √† la racine ou dans src
        df = pd.read_csv('aqi_data.csv') 
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        # Nettoyage rapide
        cols_num = ['aqi', 'pm25', 'pm10', 'co', 'no2', 'so2', 'o3']
        for col in cols_num:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        return df.dropna()
    except Exception as e:
        return None

def init_connection():
    """Connexion √† NeonDB pour le Live"""
    return st.connection("postgresql", type="sql")

def load_live_data(conn):
    """R√©cup√®re les donn√©es fraiches de Neon"""
    try:
        return conn.query('SELECT * FROM aqi_data ORDER BY timestamp DESC;', ttl="10m")
    except:
        return pd.DataFrame() # Retourne vide si erreur (table vide)

# --- NAVIGATION ---
st.sidebar.title("üîç Navigation")
page = st.sidebar.radio("Aller vers :", ["üìä Archives & Performance IA", "üî¥ Live Data (Temps R√©el)"])

# ==============================================================================
# PAGE 1 : ARCHIVES & PERFORMANCE (Le CSV)
# ==============================================================================
if page == "üìä Archives & Performance IA":
    st.title("üß† Analyse de Performance du Mod√®le")
    st.markdown("""
    Cette section utilise les **donn√©es historiques** pour √©valuer la capacit√© de l'IA √† pr√©dire la qualit√© de l'air.
    Nous simulons des pr√©dictions pass√©es pour comparer la **th√©orie vs la r√©alit√©**.
    """)

    df = load_archive_data()

    if df is not None:
        # 1. Filtres Lat√©raux
        st.sidebar.header("Param√®tres de Simulation")
        locations = df['location'].unique()
        selected_location = st.sidebar.selectbox("üìç Choisir un lieu", locations)
        
        # Filtrer par lieu
        df_loc = df[df['location'] == selected_location].sort_values('timestamp')
        
        # S√©lecteur de date pour le test
        min_date = df_loc['timestamp'].min().date()
        max_date = df_loc['timestamp'].max().date()
        
        st.sidebar.info(f"Donn√©es disponibles du {min_date} au {max_date}")
        test_date = st.sidebar.date_input("üìÖ Date √† pr√©dire", max_date, min_value=min_date, max_value=max_date)

        # 2. Pr√©paration du Mod√®le (Entra√Ænement √† la vol√©e pour la d√©mo)
        # On entra√Æne sur tout ce qui est AVANT la date choisie
        split_date = pd.Timestamp(test_date)
        train_df = df_loc[df_loc['timestamp'] < split_date]
        test_df = df_loc[df_loc['timestamp'].dt.date == split_date]

        if len(train_df) > 50 and len(test_df) > 0:
            features = ['pm25', 'no2', 'so2', 'co', 'o3'] # On utilise les polluants pour pr√©dire l'AQI
            target = 'aqi'
            
            X_train = train_df[features]
            y_train = train_df[target]
            X_test = test_df[features]
            y_test = test_df[target]

            # Entra√Ænement rapide
            model = RandomForestRegressor(n_estimators=50, random_state=42)
            model.fit(X_train, y_train)
            
            # Pr√©dictions
            y_pred = model.predict(X_test)
            test_df['predicted_aqi'] = y_pred

            # 3. Affichage des R√©sultats
            
            # M√©triques Cl√©s
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            col1, col2, col3 = st.columns(3)
            col1.metric("Date Analys√©e", f"{test_date}")
            col2.metric("Pr√©cision du Mod√®le (R¬≤)", f"{r2:.2f}", help="1.0 est parfait, 0.0 est nul")
            col3.metric("Erreur Moyenne (MAE)", f"{mae:.1f}", help="√âcart moyen entre pr√©diction et r√©alit√©")

            # Graphique : R√©alit√© vs Pr√©diction
            st.subheader("üìâ Comparatif : R√©alit√© vs Pr√©diction IA")
            
            fig = go.Figure()
            
            # Ligne R√©elle
            fig.add_trace(go.Scatter(
                x=test_df['timestamp'], 
                y=test_df['aqi'],
                mode='lines+markers',
                name='R√©alit√© (Mesur√©)',
                line=dict(color='#1f77b4', width=3)
            ))
            
            # Ligne Pr√©dite
            fig.add_trace(go.Scatter(
                x=test_df['timestamp'], 
                y=test_df['predicted_aqi'],
                mode='lines',
                name='Pr√©diction IA',
                line=dict(color='#ff7f0e', width=3, dash='dot')
            ))
            
            fig.update_layout(title=f"Evolution de l'AQI √† {selected_location} le {test_date}",
                              xaxis_title="Heure", yaxis_title="AQI", template="plotly_white")
            st.plotly_chart(fig, use_container_width=True)

            # Feature Importance (Sur quoi le mod√®le se base ?)
            st.subheader("üß™ Facteurs d'influence")
            st.markdown("Quels polluants ont le plus pes√© dans la d√©cision de l'IA ?")
            
            importance = pd.DataFrame({
                'Polluant': features,
                'Importance': model.feature_importances_
            }).sort_values(by='Importance', ascending=True)
            
            fig_imp = px.bar(importance, x='Importance', y='Polluant', orientation='h', 
                             title="Importance des variables", color='Importance', color_continuous_scale='Viridis')
            st.plotly_chart(fig_imp, use_container_width=True)

        else:
            st.warning("‚ö†Ô∏è Pas assez de donn√©es pour cette date ou date situ√©e au tout d√©but de l'historique. Choisissez une date plus r√©cente.")

    else:
        st.error("‚ùå Fichier 'aqi_data.csv' introuvable. Veuillez l'uploader √† la racine du projet.")

# ==============================================================================
# PAGE 2 : LIVE DATA (NeonDB)
# ==============================================================================
elif page == "üî¥ Live Data (Temps R√©el)":
    st.title("üì° Monitoring en Temps R√©el")
    st.markdown("Connexion directe √† la base de donn√©es **NeonDB**. Les donn√©es apparaissent ici d√®s qu'elles sont collect√©es par le scraper.")

    conn = init_connection()
    df_live = load_live_data(conn)

    if not df_live.empty:
        # Conversion date
        df_live['timestamp'] = pd.to_datetime(df_live['timestamp'])
        
        # Dernier relev√©
        latest = df_live.iloc[0]
        st.info(f"Derni√®re mise √† jour : {latest['timestamp']}")

        # KPI Cards pour les villes principales
        st.subheader("üåç Situation Actuelle")
        cols = st.columns(4)
        
        # On prend les 4 villes les plus r√©centes
        recent_cities = df_live.drop_duplicates(subset=['location']).head(4)
        
        for index, (i, row) in enumerate(recent_cities.iterrows()):
            with cols[index]:
                color = get_aqi_color(row['aqi'])
                st.markdown(f"""
                <div style="background-color: {color}; padding: 10px; border-radius: 10px; color: black; text-align: center;">
                    <h3>{row['location']}</h3>
                    <h1>{int(row['aqi'])}</h1>
                    <p>AQI</p>
                </div>
                """, unsafe_allow_html=True)

        # Tableau de donn√©es brutes
        st.subheader("üìù Derniers relev√©s re√ßus")
        st.dataframe(df_live)
        
        # Bouton refresh manuel
        if st.button("üîÑ Actualiser les donn√©es"):
            st.rerun()

    else:
        st.container()
        st.warning("‚è≥ La base de donn√©es est actuellement vide.")
        st.markdown("""
        ### Pourquoi est-ce vide ?
        C'est normal ! Vous venez de cr√©er une nouvelle infrastructure.
        * Le **Scraper** va s'ex√©cuter automatiquement √† la prochaine heure programm√©e.
        * D√®s que le premier relev√© sera captur√©, cette page s'animera automatiquement.
        
        Revenez dans une heure pour voir les premiers points appara√Ætre ! üå±
        """)
